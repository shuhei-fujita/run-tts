02. ゼロから数百万のユーザーまでスケールします。

---

何百万人ものユーザーをサポートするシステムを設計することは困難であり、継続的な改良と無限の改善が必要な旅です。. この章では、単一のユーザーをサポートし、徐々にスケールアップして数百万のユーザーにサービスを提供するシステムを構築します。. この章を読んだ後、システム設計の面接の質問を解読するのに役立ついくつかのテクニックを習得します。.

単一サーバーのセットアップ。
千マイルの旅は単一のステップから始まり、複雑なシステムの構築も例外ではありません。. 簡単なことから始めると、すべてが単一のサーバーで実行されています。. 図1は、Webアプリ、データベース、キャッシュなど、すべてが1つのサーバーで実行されている単一のサーバーセットアップの図を示しています。.



図1。
この設定を理解するには、リクエストフローとトラフィックソースを調査すると役立ちます。. まず、リクエストフローを見てみましょう(図2)。.



図2。
1。. ユーザーは、api.mysite.comなどのドメイン名を介してWebサイトにアクセスします。. 通常、ドメインネームシステム(DNS)はサードパーティが提供する有料サービスであり、サーバーではホストされません。.

2。. インターネットプロトコル(IP)アドレスは、ブラウザまたはモバイルアプリに返されます。. この例では、IPアドレス15.125.23.214が返されます。.

3。. IPアドレスが取得されると、ハイパーテキスト転送プロトコル(HTTP)[1]リクエストがWebサーバーに直接送信されます。.

4。. Webサーバーは、レンダリングのためにHTMLページまたはJSON応答を返します。.

次に、交通源を調べましょう。. Webサーバーへのトラフィックは、Webアプリケーションとモバイルアプリケーションの2つのソースから取得されます。.

Webアプリケーション:サーバー側の言語(Java、Pythonなど)の組み合わせを使用します。.)ビジネスロジック、ストレージなどを処理します。.、およびプレゼンテーション用のクライアント側言語(HTMLおよびJavaScript)。.

モバイルアプリケーション:HTTPプロトコルは、モバイルアプリとWebサーバー間の通信プロトコルです。. JavaScriptオブジェクト表記(JSON)は、その単純さのためにデータを転送するために一般的に使用されるAPI応答形式です。. JSON形式のAPI応答の例を以下に示します。

GET / users / 12 – id = 12のユーザーオブジェクトを取得します。

{。
"id":12、。
"firstName": "John"、。
"lastName": "Smith"、。
"住所":{。
"streetAddress": "21 2nd Street"、。
"都市": "ニューヨーク"、。
"状態": "NY"、。
"postalCode":10021。
}、。
"電話番号":[。
「212 555-1234」、
「646 555-4567」。
]。
}。
データベース。
ユーザーベースの成長に伴い、1つのサーバーでは不十分であり、複数のサーバーが必要です。1つはWeb /モバイルトラフィック用、もう1つはデータベース用です(図3)。. Web /モバイルトラフィック(Webティア)とデータベース(データティア)サーバーを分離すると、サーバーを個別にスケーリングできます。.



図3。
使用するデータベース。?
従来のリレーショナルデータベースと非リレーショナルデータベースのどちらかを選択できます。. それらの違いを調べましょう。.

リレーショナルデータベースは、リレーショナルデータベース管理システム(RDBMS)またはSQLデータベースとも呼ばれます。. 最も人気のあるものは、MySQL、Oracleデータベース、PostgreSQLなどです。. 関係データベースは、テーブルと行にデータを表して保存します。. さまざまなデータベーステーブル間でSQLを使用して結合操作を実行できます。.

非リレーショナルデータベースは、NoSQLデータベースとも呼ばれます。. 人気のあるものは、CouchDB、Neo4j、Cassandra、HBase、Amazon DynamoDBなどです。. [2]。. これらのデータベースは、キーバリューストア、グラフストア、列ストア、ドキュメントストアの4つのカテゴリに分類されます。. 参加する操作は、通常、非リレーショナルデータベースではサポートされていません。.

ほとんどの開発者にとって、リレーショナルデータベースは40年以上前から存在しており、歴史的にうまく機能しているため、最良の選択肢です。. ただし、リレーショナルデータベースが特定のユースケースに適さない場合は、リレーショナルデータベースを超えて調査することが重要です。. 以下の場合、非リレーショナルデータベースが正しい選択になる可能性があります。

アプリケーションには超低レイテンシが必要です。.

データが構造化されていないか、リレーショナルデータがありません。.

データ(JSON、XML、YAMLなど)のシリアル化とシリアル化解除のみが必要です。.)。.

大量のデータを保存する必要があります。.

垂直スケーリングと水平スケーリング。
「スケールアップ」と呼ばれる垂直スケーリングとは、より多くの電力(CPU、RAMなど)を追加するプロセスを意味します。.)サーバーに。. 「スケールアウト」と呼ばれる水平スケーリングでは、リソースのプールにサーバーを追加することでスケーリングできます。.

トラフィックが少ない場合、垂直スケーリングが優れたオプションであり、垂直スケーリングのシンプルさが主な利点です。. 残念ながら、それは深刻な制限を伴います。.

垂直スケーリングには厳しい制限があります。. 無制限のCPUとメモリを単一のサーバーに追加することは不可能です。.

垂直スケーリングにはフェイルオーバーと冗長性がありません。. 1つのサーバーがダウンすると、Webサイト/アプリは完全にダウンします。.

水平スケーリングは、垂直スケーリングの制限により、大規模アプリケーションでより望ましいものです。.

以前の設計では、ユーザーはWebサーバーに直接接続されています。. Webサーバーがオフラインの場合、ユーザーはWebサイトにアクセスできません。. 別のシナリオでは、多くのユーザーが同時にWebサーバーにアクセスし、それがWebサーバーの負荷制限に達した場合、ユーザーは通常、応答が遅くなるか、サーバーへの接続に失敗します。. ロードバランサーは、これらの問題に対処するための最良の技術です。.

バランサーをロードします。
ロードバランサーは、ロードバランスセットで定義されたWebサーバー間で着信トラフィックを均等に分散します。. 図4は、ロードバランサーのしくみを示しています。.



図4。
図4に示すように、ユーザーはロードバランサーのパブリックIPに直接接続します。. このセットアップにより、Webサーバーはクライアントから直接アクセスできなくなります。. セキュリティを強化するために、プライベートIPはサーバー間の通信に使用されます。. プライベートIPは、同じネットワーク内のサーバー間でのみ到達可能なIPアドレスです。ただし、インターネット経由でアクセスすることはできません。. ロードバランサーは、プライベートIPを介してWebサーバーと通信します。.

図4では、ロードバランサーと2番目のWebサーバーが追加された後、フェイルオーバーの問題を解決し、Web層の可用性を向上させました。. 詳細は以下で説明されています。

サーバー1がオフラインになると、すべてのトラフィックがサーバー2にルーティングされます。. これにより、Webサイトがオフラインになるのを防ぎます。. また、負荷のバランスをとるために、サーバープールに新しい正常なWebサーバーを追加します。.

Webサイトのトラフィックが急速に増加し、2台のサーバーではトラフィックを処理するのに十分でない場合、ロードバランサーはこの問題を優雅に処理できます。. Webサーバープールにサーバーを追加するだけで、ロードバランサーが自動的にリクエストの送信を開始します。.

これでWebティアは良く見えますが、データティアはどうですか。? 現在の設計には1つのデータベースがあるため、フェイルオーバーと冗長性はサポートされていません。. データベースの複製は、これらの問題に対処するための一般的な手法です。. 見てみましょう。.

データベースの複製。
ウィキペディアから引用:「データベースの複製は多くのデータベース管理システムで使用でき、通常はオリジナル(マスター)とコピー(スレーブ)の間のマスター/スレーブ関係があります」[3]。.

マスターデータベースは通常、書き込み操作のみをサポートします。. slaveデータベースは、マスターデータベースからデータのコピーを取得し、読み取り操作のみをサポートします。. 挿入、削除、更新などのすべてのデータ変更コマンドをマスターデータベースに送信する必要があります。. ほとんどのアプリケーションでは、書き込みに対する読み取りの比率がはるかに高くなります。したがって、システム内のスレーブデータベースの数は通常、マスターデータベースの数よりも多くなります。. 図5は、複数のスレーブデータベースを備えたマスターデータベースを示しています。.



図5。
データベースレプリケーションの利点:。

より良いパフォーマンス:マスタースレーブモデルでは、すべての書き込みと更新がマスターノードで行われます。一方、読み取り操作はスレーブノード全体に分散されます。. このモデルでは、より多くのクエリを並行して処理できるため、パフォーマンスが向上します。.

信頼性:台風や地震などの自然災害によってデータベースサーバーの1つが破壊された場合でも、データは保持されます。. データは複数の場所で複製されるため、データの損失について心配する必要はありません。.

可用性の向上:別のデータベースサーバーに保存されているデータにアクセスできるため、データベースがオフラインであっても、Webサイトは動作し続けます。.

前のセクションでは、ロードバランサーがシステムの可用性の向上にどのように役立つかについて説明しました。. ここでも同じ質問をします。データベースの1つがオフラインになった場合はどうでしょうか。? 図5で説明されている建築設計は、このケースを処理できます。

スレーブデータベースが1つしかなく、オフラインになっている場合、読み取り操作は一時的にマスターデータベースに転送されます。. 問題が見つかるとすぐに、新しいスレーブデータベースが古いデータベースに取って代わります。. 複数のスレーブデータベースが利用可能な場合、読み取り操作は他の正常なスレーブデータベースにリダイレクトされます。. 新しいデータベースサーバーが古いデータベースサーバーを置き換えます。.

マスターデータベースがオフラインになると、スレーブデータベースが新しいマスターに昇格します。. すべてのデータベース操作は、新しいマスターデータベースで一時的に実行されます。. 新しいスレーブデータベースは、データレプリケーションの古いデータベースをすぐに置き換えます。. スレーブデータベースのデータが最新でない可能性があるため、生産システムでは、新しいマスターの宣伝はより複雑です。. 不足しているデータは、データ回復スクリプトを実行して更新する必要があります。. マルチマスターや循環複製などの他の複製方法が役立つ可能性がありますが、それらの設定はより複雑です。そして、彼らの議論はこのコースの範囲を超えています。. 興味のある読者は、リストされた参照資料[4] [5]を参照する必要があります。.

図6は、ロードバランサーとデータベースのレプリケーションを追加した後のシステム設計を示しています。.



図6。
デザインを見てみましょう。

ユーザーは、DNSからロードバランサーのIPアドレスを取得します。

ユーザーはロードバランサーをこのIPアドレスに接続します。.

HTTPリクエストは、サーバー1またはサーバー2のいずれかにルーティングされます。.

Webサーバーはスレーブデータベースからユーザーデータを読み取ります。.

Webサーバーは、データ変更操作をマスターデータベースにルーティングします。. これには、書き込み、更新、および削除操作が含まれます。.

これで、Webおよびデータ階層がしっかりと理解できました。負荷/応答時間を改善する時が来ました。. これは、キャッシュレイヤーを追加し、静的コンテンツ(JavaScript / CSS / image / videoファイル)をコンテンツ配信ネットワーク(CDN)にシフトすることで実行できます。.

キャッシュ。
キャッシュは一時的なストレージエリアであり、高価な応答や頻繁にアクセスされるデータの結果をメモリに保存するため、後続のリクエストがより迅速に提供されます。. 図6に示すように、新しいWebページが読み込まれるたびに、1つ以上のデータベースコールが実行されてデータがフェッチされます。. アプリケーションのパフォーマンスは、データベースを繰り返し呼び出すことによって大きく影響されます。. キャッシュはこの問題を軽減できます。.

キャッシュティア。
キャッシュ層は一時的なデータストア層であり、データベースよりもはるかに高速です。. 個別のキャッシュ層を持つことの利点には、システムパフォーマンスの向上、データベースワークロードを削減する機能、キャッシュ層を個別にスケーリングする機能が含まれます。. 図7は、キャッシュサーバーの可能なセットアップを示しています。



図7。
リクエストを受信した後、Webサーバーはまずキャッシュに利用可能な応答があるかどうかを確認します。. ある場合は、データをクライアントに送り返します。. そうでない場合は、データベースをクエリし、応答をキャッシュに保存して、クライアントに送り返します。. このキャッシュ戦略は、リードスルーキャッシュと呼ばれます。. データの種類、サイズ、アクセスパターンに応じて、他のキャッシュ戦略を利用できます。. 以前の研究では、さまざまなキャッシング戦略がどのように機能するかを説明しています[6]。.

ほとんどのキャッシュサーバーは一般的なプログラミング言語のAPIを提供するため、キャッシュサーバーとのやり取りは簡単です。. 次のコードスニペットは、典型的なMemcached APIを示しています。

秒= 1。
cache.set( 'myKey、' hi there '、3600 * SECONDS)。
cache.get( 'myKey')。
キャッシュを使用するための考慮事項。
キャッシュシステムを使用するためのいくつかの考慮事項を次に示します。

キャッシュをいつ使用するかを決定します。. データが頻繁に読み取られるが、まれに変更される場合は、キャッシュの使用を検討してください。. キャッシュされたデータは揮発性メモリに保存されるため、キャッシュサーバーはデータの永続化には理想的ではありません。. たとえば、キャッシュサーバーが再起動すると、メモリ内のすべてのデータが失われます。. したがって、重要なデータは永続的なデータストアに保存する必要があります。.

有効期限ポリシー。. 有効期限ポリシーを実装することは良い習慣です。. キャッシュされたデータの有効期限が切れると、キャッシュから削除されます。. 有効期限ポリシーがない場合、キャッシュされたデータはメモリに永続的に保存されます。. これにより、システムがデータベースからデータを頻繁にリロードするため、有効期限を短くしすぎないようにすることをお勧めします。. 一方、データが古くなる可能性がある場合は、有効期限を長くしすぎないようにすることをお勧めします。.

一貫性:これには、データストアとキャッシュを同期させておく必要があります。. データストアとキャッシュでのデータ変更操作が単一のトランザクションにないため、不整合が発生する可能性があります。. 複数の領域をスケーリングする場合、データストアとキャッシュ間の一貫性を維持することは困難です。. 詳細については、Facebook [7]が発行した「FacebookでのMemcacheのスケーリング」というタイトルの論文を参照してください。.

障害の軽減:単一のキャッシュサーバーは、Wikipediaで次のように定義されている潜在的な単一障害点(SPOF)を表します。「単一障害点(SPOF)は、システムが失敗した場合にシステム全体を停止するシステムの一部です。動作しない」[8]。. その結果、SPOFを回避するために、異なるデータセンターにまたがる複数のキャッシュサーバーが推奨されます。もう1つの推奨されるアプローチは、必要なメモリを特定の割合で過剰プロビジョン化することです。. これは、メモリの使用量が増加するにつれてバッファを提供します。.



図8。
立ち退きポリシー:キャッシュがいっぱいになると、アイテムをキャッシュに追加する要求があると、既存のアイテムが削除される可能性があります。. これはキャッシュエビクションと呼ばれます。. 最新使用(LRU)は、最も人気のあるキャッシュ立ち退きポリシーです。. 最小使用頻度(LFU)やファーストインファーストアウト(FIFO)などの他の立ち退きポリシーは、さまざまな使用例を満たすために採用できます。.
コンテンツ配信ネットワーク(CDN)。
CDNは、静的コンテンツの配信に使用される地理的に分散したサーバーのネットワークです。. CDNサーバーは、画像、ビデオ、CSS、JavaScriptファイルなどの静的コンテンツをキャッシュします。.

動的コンテンツのキャッシュは比較的新しい概念であり、このコースの範囲を超えています。. リクエストパス、クエリ文字列、Cookie、およびリクエストヘッダーに基づくHTMLページのキャッシュを可能にします。. これの詳細については、参考資料[9]に記載されている記事を参照してください。. このコースでは、CDNを使用して静的コンテンツをキャッシュする方法に焦点を当てます。.

CDNが高レベルでどのように機能するかを次に示します。ユーザーがWebサイトにアクセスすると、ユーザーに最も近いCDNサーバーが静的なコンテンツを配信します。. 直感的には、CDNサーバーのユーザー数が多いほど、Webサイトの読み込みが遅くなります。. たとえば、CDNサーバーがサンフランシスコにある場合、ロサンゼルスのユーザーはヨーロッパのユーザーよりも速くコンテンツを取得できます。. 図9は、CDNが読み込み時間をどのように改善するかを示す良い例です。.



図9。
図10は、CDNワークフローを示しています。.



図10。
1。. ユーザーAは、イメージURLを使用してimage.pngを取得しようとします。 URLのドメインはCDNプロバイダーによって提供されます。. 次の2つの画像URLは、AmazonおよびAkamai CDNでどのような画像URLが表示されるかを示すために使用されるサンプルです。

https://mysite.cloudfront.net/logo.jpg。

https://mysite.akamai.com/image-manager/img/logo.jpg。

2。. CDNサーバーがキャッシュにimage.pngを持たない場合、CDNサーバーは原点からファイルを要求します。これは、WebサーバーまたはAmazon S3などのオンラインストレージである可能性があります。.

3。. 原点はimage.pngをCDNサーバーに返します。CDNサーバーには、オプションのHTTPヘッダーTime-to-Live(TTL)が含まれており、画像がキャッシュされる時間を記述します。.

4。. CDNは画像をキャッシュし、ユーザーAに返します。TTLの有効期限が切れるまで、画像はCDNにキャッシュされたままです。.

5。. ユーザーBは、同じ画像を取得するためのリクエストを送信します。.

6。. TTLの有効期限が切れていない限り、画像はキャッシュから返されます。.

CDNの使用に関する考慮事項。
コスト:CDNはサードパーティプロバイダーによって実行され、CDNに出入りするデータ転送に対して課金されます。めったに使用されないアセットをキャッシュしても大きなメリットはないため、CDNからそれらを移動することを検討する必要があります。

適切なキャッシュの有効期限の設定:時間に敏感なコンテンツの場合、キャッシュの有効期限を設定することが重要です。. キャッシュの有効期限は長すぎず、短すぎてもいけません。. 長すぎると、コンテンツが新鮮でなくなる可能性があります。. 短すぎると、オリジンサーバーからCDNへのコンテンツの再読み込みが繰り返される可能性があります。

CDNフォールバック:Webサイト/アプリケーションがCDN障害にどのように対処するかを検討する必要があります。. 一時的なCDN停止がある場合、クライアントは問題を検出し、発信元にリソースを要求できる必要があります。.

ファイルの無効化:次の操作のいずれかを実行することにより、有効期限が切れる前にCDNからファイルを削除できます。

CDNベンダーが提供するAPIを使用してCDNオブジェクトを検証します。.

オブジェクトのバージョンを使用して、オブジェクトの別のバージョンを提供します。. オブジェクトをバージョン化するには、バージョン番号などのパラメーターをURLに追加できます。. たとえば、バージョン番号2がクエリ文字列image.pngに追加されます。?v = 2。.

図11は、CDNとキャッシュが追加された後の設計を示しています。.



図11。
1。. 静的資産(JS、CSS、画像など).、) Webサーバーではサービスが提供されなくなりました。. 彼らはより良いパフォーマンスのためにCDNから取得されます。.

2。. データベースの負荷は、データのキャッシュによって軽減されます。.

無国籍のウェブ層。
次に、Webティアを水平にスケーリングすることを検討します。. そのためには、状態(ユーザーセッションデータなど)をWeb層の外に移動する必要があります。. セッションデータをリレーショナルデータベースやNoSQLなどの永続的なストレージに格納することをお勧めします。クラスター内の各Webサーバーは、データベースから状態データにアクセスできます。. これは無国籍のWebティアと呼ばれます。.

風格のある建築。
状態の良いサーバーと状態のないサーバーには、いくつかの重要な違いがあります。. 状態の良いサーバーは、あるリクエストから次のリクエストまでのクライアントデータ(状態)を記憶します。. 無国籍サーバーは状態情報を保持しません。.

図12は、風格のあるアーキテクチャの例を示しています。.



図12。
図12では、ユーザーAのセッションデータとプロファイルイメージがサーバー1に保存されています。. ユーザーAを認証するには、HTTPリクエストをサーバー1にルーティングする必要があります。. サーバー2などの他のサーバーにリクエストが送信された場合、サーバー2にユーザーAのセッションデータが含まれていないため、認証は失敗します。. 同様に、ユーザーBからのすべてのHTTPリクエストはサーバー2にルーティングする必要があります。ユーザーCからのすべてのリクエストはサーバー3に送信する必要があります。.

問題は、同じクライアントからのすべてのリクエストを同じサーバーにルーティングする必要があることです。. これは、ほとんどのロードバランサー[10]で粘着性のあるセッションで実行できます。ただし、これはオーバーヘッドを追加します。. このアプローチでは、サーバーの追加または削除がはるかに困難です。. また、サーバーの障害を処理することも困難です。.

無国籍建築。
図13は、無国籍のアーキテクチャを示しています。.



図13。
このステートレスアーキテクチャでは、ユーザーからのHTTPリクエストを任意のWebサーバーに送信して、共有データストアからステートデータをフェッチできます。. 州のデータは共有データストアに保存され、Webサーバーには保存されません。. 無国籍システムは、よりシンプルで、より堅 ⁇ で、スケーラブルです。.

図14は、無国籍のWeb層を使用した更新された設計を示しています。.



図14。
図14では、セッションデータをWeb層の外に移動し、永続的なデータストアに保存します。. 共有データストアは、リレーショナルデータベース、Memcached / Redis、NoSQLなどです。. スケーリングが簡単なため、NoSQLデータストアが選択されます。. 自動スケーリングとは、トラフィック負荷に基づいてWebサーバーを自動的に追加または削除することを意味します。. 状態データがWebサーバーから削除された後、トラフィック負荷に基づいてサーバーを追加または削除することにより、Web層の自動スケーリングを簡単に実現できます。.

あなたのウェブサイトは急速に成長し、国際的にかなりの数のユーザーを魅了しています。. 可用性を向上させ、より広い地理的領域にわたってより良いユーザーエクスペリエンスを提供するには、複数のデータセンターをサポートすることが重要です。.

データセンター。
図15は、2つのデータセンターを使用したセットアップの例を示しています。. 通常の運用では、ユーザーは地理ルート(地理ルートとも呼ばれます)に最も近いデータセンターに地理DNSルート化され、US-Eastではx%、US-Westでは(100 – x)%のトラフィックが分割されます。. geoDNSは、ユーザーの場所に基づいてドメイン名をIPアドレスに解決できるDNSサービスです。.



図15。
データセンターが大幅に停止した場合は、すべてのトラフィックを正常なデータセンターに転送します。. 図16では、データセンター2(米国西部)がオフラインであり、トラフィックの100%がデータセンター1(米国東部)にルーティングされています。.



図16。
マルチデータセンターのセットアップを実現するには、いくつかの技術的な課題を解決する必要があります。

トラフィックリダイレクト:トラフィックを正しいデータセンターに誘導するには、効果的なツールが必要です。. GeoDNSを使用して、ユーザーがどこにいるかによって、最寄りのデータセンターにトラフィックを誘導できます。.

データ同期:異なる地域のユーザーは、異なるローカルデータベースまたはキャッシュを使用できます。. フェイルオーバーの場合、トラフィックはデータが利用できないデータセンターにルーティングされる可能性があります。. 一般的な戦略は、複数のデータセンター間でデータを複製することです。. 以前の調査では、Netflixが非同期マルチデータセンターレプリケーションを実装する方法を示しています[11]。.

テストと展開:マルチデータセンターのセットアップでは、さまざまな場所でWebサイト/アプリケーションをテストすることが重要です。. 自動展開ツールは、すべてのデータセンターを通じてサービスを一貫させるために不可欠です[11]。.

システムをさらにスケーリングするには、システムのさまざまなコンポーネントを切り離して、それらを個別にスケーリングできるようにする必要があります。. メッセージングキューは、この問題を解決するために多くの実世界の分散システムで採用されている重要な戦略です。.

メッセージキュー。
メッセージキューは、非同期通信をサポートするメモリに保存されている耐久性のあるコンポーネントです。. バッファとして機能し、非同期要求を配布します。. メッセージキューの基本的なアーキテクチャはシンプルです。. プロデューサー/パブリッシャーと呼ばれる入力サービスは、メッセージを作成し、メッセージキューに公開します。. 消費者/サブスクライバーと呼ばれる他のサービスまたはサーバーは、キューに接続し、メッセージによって定義されたアクションを実行します。. モデルを図17に示します。.



図17。
デカップリングにより、メッセージキューはスケーラブルで信頼性の高いアプリケーションを構築するための好ましいアーキテクチャになります。. メッセージキューを使用すると、消費者がメッセージを処理できないときに、プロデューサーはキューにメッセージを投稿できます。. プロデューサーが利用できない場合でも、消費者はキューからメッセージを読むことができます。.

次のユースケースを考慮してください。アプリケーションは、トリミング、シャープニング、ぼかしなど、写真のカスタマイズをサポートしています。. これらのカスタマイズタスクは完了するまでに時間がかかります。. 図18では、Webサーバーが写真処理ジョブをメッセージキューに公開しています。. 写真処理作業員は、メッセージキューからジョブを取得し、写真のカスタマイズタスクを非同期で実行します。. プロデューサーと消費者は独立してスケーリングできます。. キューのサイズが大きくなると、処理時間を短縮するために、より多くのワーカーが追加されます。. ただし、ほとんどの場合、キューが空の場合、労働者の数を減らすことができます。.



図18。
ロギング、メトリック、自動化。
いくつかのサーバーで実行される小さなWebサイトで作業する場合、ロギング、メトリック、および自動化のサポートは優れた方法ですが、必須ではありません。. ただし、サイトが大企業にサービスを提供するようになった今、これらのツールへの投資は不可欠です。.

ロギング:エラーログの監視は、システム内のエラーや問題を特定するのに役立つため、重要です。. サーバーレベルでエラーログを監視したり、ツールを使用して集中型サービスに集約したりして、簡単に検索および表示できます。.

メトリック:さまざまな種類のメトリックを収集することで、ビジネスに関する洞察を得て、システムの健康状態を理解することができます。. 以下のメトリックのいくつかは役に立ちます。

ホストレベルのメトリック:CPU、メモリ、ディスクI / Oなど.

集計レベルのメトリック:たとえば、データベース層全体のパフォーマンス、キャッシュ層など。.

主要なビジネス指標:毎日のアクティブユーザー、保持、収益など.

自動化:システムが大きく複雑になった場合、自動化ツールを構築または活用して生産性を向上させる必要があります。. 継続的な統合は、各コードチェックインが自動化によって検証され、チームが問題を早期に検出できるようにする良い方法です。. さらに、ビルド、テスト、デプロイプロセスなどの自動化。. 開発者の生産性を大幅に向上させることができます。.

メッセージキューとさまざまなツールを追加します。

図19は、更新された設計を示しています。. スペースの制約により、図に表示されているデータセンターは1つだけです。.

1。. 設計にはメッセージキューが含まれており、システムをより緩く結合し、障害に強いものにするのに役立ちます。.

2。. ロギング、監視、メトリック、自動化ツールが含まれています。.



図19。
データが毎日増加するにつれて、データベースはより過負荷になります。. データ層を拡大する時が来ました。.

データベースのスケーリング。
データベーススケーリングには、垂直スケーリングと水平スケーリングの2つの広範なアプローチがあります。.

垂直スケーリング。
垂直スケーリングは、スケールアップとも呼ばれ、より多くのパワー(CPU、RAM、ディスクなど)を追加することによるスケーリングです。.)既存のマシンに。. 強力なデータベースサーバーがいくつかあります。. Amazon Relational Database Service(RDS)[12]によると、24 TBのRAMを搭載したデータベースサーバーを取得できます。この種の強力なデータベースサーバーは、多くのデータを保存および処理できます。. たとえば、2013年のstackoverflow.comには毎月1,000万人を超えるユニークビジターがいましたが、マスターデータベースは1つしかありませんでした[13]。. ただし、垂直スケーリングにはいくつかの重大な欠点があります。

CPU、RAMなどを追加できます。. データベースサーバーには、ハードウェア制限があります。. ユーザーベースが大きい場合、単一のサーバーでは不十分です。.

単一障害ポイントのリスクが高まります。.

垂直スケーリングの全体的なコストは高いです。. 強力なサーバーははるかに高価です。.

水平スケーリング。
横スケーリングは、シャーディングとも呼ばれ、サーバーを追加する習慣です。. 図20は、垂直スケーリングと水平スケーリングを比較しています。.



図20。
シャーディングは、大きなデータベースを、シャードと呼ばれるより小さく、より簡単に管理できるパーツに分離します。. 各シャードは同じスキーマを共有しますが、各シャードの実際のデータはシャードに固有です。.

図21は、データベースの破片の例を示しています。. ユーザーデータは、ユーザーIDに基づいてデータベースサーバーに割り当てられます。. データにアクセスするたびに、ハッシュ関数を使用して対応するシャードを見つけます。. この例では、user_id%4がハッシュ関数として使用されます。. 結果が0の場合、シャード0を使用してデータを保存およびフェッチします。. 結果が1の場合、シャード1が使用されます。. 同じロジックが他のシャードにも当てはまります。.



図21。
図22は、シャードデータベースのユーザーテーブルを示しています。.



図22。
シャーディング戦略を実装するときに考慮すべき最も重要な要素は、シャーディングキーの選択です。. シャーディングキー(パーティションキーと呼ばれます)は、データの分散方法を決定する1つ以上の列で構成されます。. 図22に示すように、「user_id」はシャーディングキーです。. シャードキーを使用すると、データベースクエリを正しいデータベースにルーティングすることにより、データを効率的に取得および変更できます。. シャードキーを選択する場合、最も重要な基準の1つは、データを均等に分散できるキーを選択することです。.

シャーディングはデータベースをスケーリングするための優れた手法ですが、完全なソリューションにはほど遠いです。. システムに複雑さと新しい課題を導入します。

データの再保存:1)急速な成長により単一のシャードがデータを保持できなくなった場合、データの再保存が必要です。. 2)データの分布が不均一であるため、特定の破片は他の破片よりも早く破片の枯渇を経験する可能性があります。. シャード枯渇が発生した場合は、シャード機能を更新し、データを移動する必要があります。. 一貫したハッシュは、この問題を解決するために一般的に使用される手法です。.

有名人の問題:これはホットスポットキーの問題とも呼ばれます。. 特定のシャードへの過度のアクセスは、サーバーの過負荷を引き起こす可能性があります。. Katy Perry、Justin Bieber、Lady Gagaのデータがすべて同じ破片になってしまうと想像してください。. ソーシャルアプリケーションの場合、そのシャードは読み取り操作で圧倒されます。. この問題を解決するには、有名人ごとにシャードを割り当てる必要がある場合があります。. 各シャードには、さらにパーティションが必要になる場合があります。.

参加して正規化を解除:データベースが複数のサーバー間でシャードされると、データベースシャード全体で結合操作を実行することが難しくなります。. 一般的な回避策は、クエリを単一のテーブルで実行できるようにデータベースを非正規化することです。.

図23では、急速に増加するデータトラフィックをサポートするためにデータベースをシャードしています。. 同時に、非リレーショナル機能の一部はNoSQLデータストアに移動され、データベースの負荷が軽減されます。. 以下は、NoSQLの多くの使用例をカバーする記事です[14]。.



図23。
何百万ものユーザーとそれ以降。
システムのスケーリングは反復プロセスです。. この章で学んだことをいじることは、私たちを遠くへ連れて行くことができます。. 何百万人ものユーザーを超えてスケーリングするには、より微調整と新しい戦略が必要です。. たとえば、システムを最適化し、システムをさらに小さなサービスに分離する必要がある場合があります。. この章で学んだすべてのテクニックは、新しい課題に取り組むための優れた基盤を提供するはずです。. この章を締めくくるために、何百万ものユーザーをサポートするためにシステムをどのようにスケーリングするかについての要約を提供します。

Webティアを無国籍に保ちます。

すべての階層で冗長性を構築します。

できる限りデータをキャッシュします。

複数のデータセンターをサポートします。

CDNで静的アセットをホストします。

シャーディングしてデータ層をスケーリングします。

階層を個々のサービスに分割します。

システムを監視し、自動化ツールを使用します。

これまでのご参加、おめでとうございます。! 今度は背中を軽く叩いてください。. よくやった。!
